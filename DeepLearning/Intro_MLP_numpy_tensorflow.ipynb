{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Backpropagation and Multilayer Neural Networks\n",
    "\n",
    "### Goals: \n",
    "- Intro: train a neural network with high level framework `Keras`\n",
    "- Diving deep: implement a real gradient descent in `Numpy`\n",
    "- Auto-differentiation: the basics of `TensorFlow`\n",
    "\n",
    "### Dataset:\n",
    "- Digits: 10 class handwritten digits\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1be1e40901bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# display figures in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAElCAYAAAAcMawqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cd8a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(digits.images[sample_index], cmap=plt.cm.gray_r,\n",
    "           interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % digits.target[sample_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- normalization\n",
    "- train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.asarray(digits.data, dtype='float32')\n",
    "target = np.asarray(digits.target, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.15, random_state=37)\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the one of the transformed sample (after feature standardization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAE5CAYAAABoJW7KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\namAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cba0828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[sample_index].reshape(8, 8),\n",
    "           cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"transformed sample\\n(standardization)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaler objects makes it possible to recover the original sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAElCAYAAAAcMawqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f226fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(scaler.inverse_transform(X_train[sample_index]).reshape(8, 8),\n",
    "           cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"original sample\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1527, 64) (1527,)\n",
      "(270, 64) (270,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Feed Forward NN with Keras\n",
    "\n",
    "Objectives of this section:\n",
    "\n",
    "- Build and train a first feedforward network using `Keras`\n",
    "    - https://keras.io/getting-started/sequential-model-guide/\n",
    "- Experiment with different optimizers, activations, size of layers, initializations\n",
    "\n",
    "### a) Keras Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a first neural network we need to turn the target variable into a vector \"one-hot-encoding\" representation. Here are the labels of the first samples in the training set encoded as integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 5], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a utility function to convert integer-encoded categorical variables as one-hot encoded values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build and train a our first feed forward neural network using the high level API from keras:\n",
    "\n",
    "- first we define the model by stacking layers with the right dimensions\n",
    "- then we define a loss function and plug the SGD optimizer\n",
    "- then we feed the model the training data for fixed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.8044 - acc: 0.7957     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.2778 - acc: 0.9450     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1894 - acc: 0.9646     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1481 - acc: 0.9718     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1228 - acc: 0.9784     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1058 - acc: 0.9823     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0922 - acc: 0.9862     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0824 - acc: 0.9882     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0737 - acc: 0.9908     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0666 - acc: 0.9915     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0608 - acc: 0.9928     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0559 - acc: 0.9935     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0515 - acc: 0.9935     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0478 - acc: 0.9954     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0444 - acc: 0.9961     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f21acc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "N = X_train.shape[1]\n",
    "H = 100\n",
    "K = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Exercises: Impact of the Optimizer\n",
    "\n",
    "- Try to decrease the learning rate value by 10 or 100. What do you observe?\n",
    "\n",
    "- Try to increase the learning rate value to make the optimization diverge.\n",
    "\n",
    "- Configure the SGD optimizer to enable a Nesterov momentum of 0.9\n",
    "  \n",
    "Note that the keras API documentation is avaiable at:\n",
    "\n",
    "https://keras.io/\n",
    "\n",
    "It is also possible to learn more about the parameters of a class by using the question mark: type and evaluate:\n",
    "\n",
    "```python\n",
    "optimizers.SGD?\n",
    "```\n",
    "\n",
    "in a jupyter notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.9918 - acc: 0.3307     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.2880 - acc: 0.6562     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.9439 - acc: 0.7924     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.7552 - acc: 0.8389     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.6365 - acc: 0.8710     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.5544 - acc: 0.8926     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.4932 - acc: 0.9057     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.4459 - acc: 0.9155     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.4082 - acc: 0.9234     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.3770 - acc: 0.9293     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.3510 - acc: 0.9319     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.3289 - acc: 0.9371     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.3097 - acc: 0.9411     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.2930 - acc: 0.9437     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.2783 - acc: 0.9470     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12279f048>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.01),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 2.5552 - acc: 0.0675     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 2.4247 - acc: 0.0956     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 2.3019 - acc: 0.1257     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 2.1865 - acc: 0.1618     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 2.0782 - acc: 0.2017     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.9770 - acc: 0.2633     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.8827 - acc: 0.3346     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.7948 - acc: 0.4001     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.7130 - acc: 0.4499     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.6369 - acc: 0.5010     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.5664 - acc: 0.5435     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.5011 - acc: 0.5802     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.4404 - acc: 0.6084     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.3842 - acc: 0.6405     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.3321 - acc: 0.6693     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122f0f208>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 13.2701 - acc: 0.1585     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.8777 - acc: 0.2626     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 11.5582 - acc: 0.2829     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12197c3c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=1000),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.0508 - acc: 0.6876     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.2751 - acc: 0.9404     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1898 - acc: 0.9594     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1500 - acc: 0.9712     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1245 - acc: 0.9758     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1065 - acc: 0.9804     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0931 - acc: 0.9830     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0828 - acc: 0.9849     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0744 - acc: 0.9869     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0677 - acc: 0.9889     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0613 - acc: 0.9921     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0566 - acc: 0.9921     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0524 - acc: 0.9941     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0486 - acc: 0.9941     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0452 - acc: 0.9948     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122fc6b38>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.01,momentum=0.9,nesterov=True),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_sgd_and_momentum.py\n",
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)\n",
    "\n",
    "\n",
    "# Analysis:\n",
    "#\n",
    "# Setting the learning rate value to a small value (e.g. lr=0.001 on\n",
    "# this dataset) makes the model train much slower (it has not\n",
    "# converged yet after 15 epochs).\n",
    "#\n",
    "# Using momentum tends to mitigate the small learning rate / slow\n",
    "# training problem a bit.\n",
    "#\n",
    "# Setting the learning rate to a very large value (e.g. lr=10)\n",
    "# makes the model randomly bounce around a good local\n",
    "# minimum and therefore prevent it to reach a low training loss even\n",
    "# after 30 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace the SGD optimizer by the Adam optimizer from keras and run it\n",
    "  with the default parameters.\n",
    "\n",
    "- Add another hidden layer and use the \"Rectified Linear Unit\" for each\n",
    "  hidden layer. Can you still train the model with Adam with its default global\n",
    "  learning rate?\n",
    "\n",
    "- Bonus: try the Adadelta optimizer (no learning rate to set).\n",
    "\n",
    "Hint: use `optimizers.<TAB>` to tab-complete the list of implemented optimizers in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1527/1527 [==============================] - 0s - loss: 1.4668 - acc: 0.5560     \n",
      "Epoch 2/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.5413 - acc: 0.8926     \n",
      "Epoch 3/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.3298 - acc: 0.9456     \n",
      "Epoch 4/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.2383 - acc: 0.9581     \n",
      "Epoch 5/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1876 - acc: 0.9699     \n",
      "Epoch 6/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1543 - acc: 0.9712     \n",
      "Epoch 7/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1300 - acc: 0.9804     \n",
      "Epoch 8/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.1122 - acc: 0.9810     \n",
      "Epoch 9/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0981 - acc: 0.9862     \n",
      "Epoch 10/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0866 - acc: 0.9882     \n",
      "Epoch 11/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0767 - acc: 0.9902     \n",
      "Epoch 12/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0692 - acc: 0.9902     \n",
      "Epoch 13/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0626 - acc: 0.9928     \n",
      "Epoch 14/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0565 - acc: 0.9941     \n",
      "Epoch 15/15\n",
      "1527/1527 [==============================] - 0s - loss: 0.0512 - acc: 0.9941     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12408d7b8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, nb_epoch=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_adam_and_adadelta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Exercises: forward pass and generalization\n",
    "\n",
    "- Compute predictions on test set using `model.predict_classes(...)`\n",
    "- Compute average accuracy of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_accuracy_on_test_set.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the conditional probabilities of sample number 42 of the test set with `model.predict_proba(...)`\n",
    "- Derive the loss (negative log likelihood of that sample) using numpy operations\n",
    "- Compute the average negative log likelihood of the test set.\n",
    "- Compare this value to the training loss reported by keras: is the model overfitting or underfitting?\n",
    "\n",
    "Note: you might need to retrain the model with a larger number of epochs (e.g. 50) to ensure that it has fully converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_loss_on_test_set.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Home assignment: impact of initialization\n",
    "\n",
    "Let us now study the impact of a bad initialization when training\n",
    "a deep feed forward network.\n",
    "\n",
    "By default Keras dense layers use the \"Glorot Uniform\" initialization\n",
    "strategy to initialize the weight matrices:\n",
    "\n",
    "- each weight coefficient is randomly sampled from [-scale, scale]\n",
    "- scale is proportional to $\\frac{1}{\\sqrt{n_{in} + n_{out}}}$\n",
    "\n",
    "This strategy is known to work well to initialize deep neural networks\n",
    "with \"tanh\" or \"relu\" activation functions and then trained with\n",
    "standard SGD.\n",
    "\n",
    "To assess the impact of initialization let us plug an alternative init\n",
    "scheme into a 2 hidden layers networks with \"tanh\" activations.\n",
    "For the sake of the example let's use normal distributed weights\n",
    "with a manually adjustable scale (standard deviation) and see the\n",
    "impact the scale value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import initializations\n",
    "\n",
    "def normal_init(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N, init=normal_init))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K, init=normal_init))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K, init=normal_init))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "- Try the following initialization schemes and see whether\n",
    "  the SGD algorithm can successfully train the network or\n",
    "  not:\n",
    "  \n",
    "  - a very small e.g. `scale=1e-3`\n",
    "  - a larger scale e.g. `scale=1` or `10`\n",
    "  - initialize all weights to 0 (constant initialization)\n",
    "  \n",
    "- What do you observe? Can you find an explanation for those\n",
    "  outcomes?\n",
    "\n",
    "- Are better solvers such as SGD with momentum or Adam able\n",
    "  to deal better with such bad initializations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_initializations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/keras_initializations_analysis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Numpy Implementation\n",
    "\n",
    "## a) Logistic Regression\n",
    "\n",
    "In this section we will implement a logistic regression model trainable with SGD using numpy. Here are the objectives:\n",
    "\n",
    "1/ Implement a simple forward model with no hidden layer (equivalent to a logistic regression):\n",
    "note: shape, transpose of W with regards to course\n",
    "$y = softmax(\\mathbf{W} \\dot x + b)$\n",
    "\n",
    "2/ build a predict function which returns the most probable class given an input $x$\n",
    "\n",
    "3/ build an accuracy function for a batch of inputs $X$ and the corresponding expected outputs $y_{true}$\n",
    "\n",
    "4/ build a grad function which computes $\\frac{d}{dW} -\\log(softmax(W \\dot x + b))$ for an $x$ and its corresponding expected output $y_{true}$ ; check that the gradients are well defined\n",
    "\n",
    "5/ build a train function which uses the grad function output to update $\\mathbf{W}$ and $b$\n",
    "\n",
    "\n",
    "First let's define a helper function to compute the one hot encoding of an integer array for a fixed number of classes (similar to keras' `to_categorical`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(n_classes, y):\n",
    "    return np.eye(n_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(10, [0, 4, 9, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement the softmax vector function:\n",
    "\n",
    "$$\n",
    "softmax(\\mathbf{x}) = \\frac{1}{\\sum_{i=1}^{n}{e^{x_i}}}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "  e^{x_1}\\\\\\\\\n",
    "  e^{x_2}\\\\\\\\\n",
    "  \\vdots\\\\\\\\\n",
    "  e^{x_n}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that this works one vector at a time (and check that the components sum to one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(softmax([10, 2, -3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a naive implementation of softmax might not be able process a batch of activations in a single call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[10, 2, -3],\n",
    "              [-1, 5, -20]])\n",
    "print(softmax(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a way to implement softmax that works both for an individal vector of activations and for a batch of activation vectors at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax of a single vector:\n",
      "[  9.99662391e-01   3.35349373e-04   2.25956630e-06]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax(X):\n",
    "    exp = np.exp(X)\n",
    "    return exp / np.sum(exp, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "print(\"softmax of a single vector:\")\n",
    "print(softmax([10, 2, -3]))\n",
    "print(np.sum(softmax([10, 2, -3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sotfmax of 2 vectors:\n",
      "[[  9.99662391e-01   3.35349373e-04   2.25956630e-06]\n",
      " [  2.47262316e-03   9.97527377e-01   1.38536042e-11]]\n",
      "[ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"sotfmax of 2 vectors:\")\n",
    "X = np.array([[10, 2, -3],\n",
    "              [-1, 5, -20]])\n",
    "print(softmax(X))\n",
    "print(np.sum(softmax(X), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that given the true one-hot encoded class `Y_true` and and some predicted probabilities `Y_pred` returns the negative log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nll(Y_true, Y_pred):\n",
    "    # TODO\n",
    "    return 0.\n",
    "\n",
    "\n",
    "# Make sure that it works for a simple sample at a time\n",
    "print(nll([1, 0, 0], [.99, 0.01, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the nll of a very confident yet bad prediction is a much higher positive number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(nll([1, 0, 0], [0.01, 0.01, .98]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your implementation can compute the average negative log likelihood of a group of predictions: `Y_pred` and `Y_true` can therefore be past as 2D arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nll(Y_true, Y_pred):\n",
    "    Y_true, Y_pred = np.atleast_2d(Y_true), np.atleast_2d(Y_pred)\n",
    "    # TODO\n",
    "    return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that the average NLL of the following 3 almost perfect\n",
    "# predictions is close to 0\n",
    "Y_true = np.array([[0, 1, 0],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1]])\n",
    "\n",
    "Y_pred = np.array([[0,   1,    0],\n",
    "                   [.99, 0.01, 0],\n",
    "                   [0,   0,    1]])\n",
    "\n",
    "print(nll(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0100503257525\n",
      "4.60516918599\n",
      "0.0033501019175\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/numpy_nll.py\n",
    "EPSILON = 1e-8\n",
    "\n",
    "\n",
    "def nll(Y_true, Y_pred):\n",
    "    Y_true, Y_pred = np.atleast_2d(Y_true), np.atleast_2d(Y_pred)\n",
    "    loglikelihoods = np.sum(np.log(EPSILON + Y_pred) * Y_true, axis=1)\n",
    "    return -np.mean(loglikelihoods)\n",
    "\n",
    "\n",
    "# Make sure that it works for a simple sample at a time\n",
    "print(nll([1, 0, 0], [.99, 0.01, 0]))\n",
    "\n",
    "# Check that the nll of a very confident yet bad prediction\n",
    "# is very high:\n",
    "print(nll([1, 0, 0], [0.01, 0.01, .98]))\n",
    "\n",
    "# Check that the average NLL of the following 3 almost perfect\n",
    "# predictions is close to 0\n",
    "Y_true = np.array([[0, 1, 0],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1]])\n",
    "\n",
    "Y_pred = np.array([[0,   1,    0],\n",
    "                   [.99, 0.01, 0],\n",
    "                   [0,   0,    1]])\n",
    "print(nll(Y_true, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now study the following linear model trainable by SGD, **one sample at a time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = np.random.uniform(size=(input_size, output_size), high=0.1, low=-0.1)\n",
    "        self.b = np.random.uniform(size=(output_size), high=0.1, low=-0.1)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Z = np.dot(X, self.W) + self.b\n",
    "        return softmax(Z)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            return np.argmax(self.forward(X))\n",
    "        else:\n",
    "            return np.argmax(self.forward(X), axis=1)\n",
    "    \n",
    "    def grad_loss(self, x, y_true):\n",
    "        y_pred = self.forward(x)\n",
    "        dnll_output =  y_pred - one_hot(self.output_size, y_true)\n",
    "        grad_W = np.outer(x, dnll_output)\n",
    "        grad_b = dnll_output\n",
    "        grads = {\"W\": grad_W, \"b\": grad_b}\n",
    "        return grads\n",
    "    \n",
    "    def train(self, x, y, learning_rate):\n",
    "        # Traditional SGD update without momentum\n",
    "        grads = self.grad_loss(x, y)\n",
    "        self.W = self.W - learning_rate * grads[\"W\"]\n",
    "        self.b = self.b - learning_rate * grads[\"b\"]      \n",
    "        \n",
    "    def loss(self, x, y):\n",
    "        return nll(one_hot(self.output_size, y), self.forward(x))\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_preds = np.argmax(self.forward(X), axis=1)\n",
    "        return np.mean(y_preds == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the untrained model:\n",
      "train loss: 2.5727, train acc: 0.050, test acc: 0.096\n"
     ]
    }
   ],
   "source": [
    "# Build a model and test its forward inference\n",
    "n_features = X_train.shape[1]\n",
    "n_classes = Y_train.shape[1]\n",
    "lr = LogisticRegression(n_features, n_classes)\n",
    "\n",
    "print(\"Evaluation of the untrained model:\")\n",
    "train_loss = lr.loss(X_train, y_train)\n",
    "train_acc = lr.accuracy(X_train, y_train)\n",
    "test_acc = lr.accuracy(X_test, y_test)\n",
    "\n",
    "print(\"train loss: %0.4f, train acc: %0.3f, test acc: %0.3f\"\n",
    "      % (train_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFyCAYAAABlU6npAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12429d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the untrained model on the first example\n",
    "sample_idx = 0\n",
    "plt.plot(lr.forward(X_train[sample_idx]), linestyle='-', label='prediction')\n",
    "plt.plot(one_hot(10, y_train[sample_idx]), linestyle='--', label='true')\n",
    "plt.title('output probabilities')\n",
    "plt.legend()\n",
    "print(lr.predict(X_train[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update #0, train loss: 2.5445, train acc: 0.084, test acc: 0.130\n",
      "Update #100, train loss: 1.3833, train acc: 0.700, test acc: 0.715\n",
      "Update #200, train loss: 0.8916, train acc: 0.859, test acc: 0.881\n",
      "Update #300, train loss: 0.6553, train acc: 0.898, test acc: 0.922\n",
      "Update #400, train loss: 0.5439, train acc: 0.907, test acc: 0.926\n",
      "Update #500, train loss: 0.4692, train acc: 0.916, test acc: 0.930\n",
      "Update #600, train loss: 0.4110, train acc: 0.926, test acc: 0.933\n",
      "Update #700, train loss: 0.3727, train acc: 0.928, test acc: 0.948\n",
      "Update #800, train loss: 0.3523, train acc: 0.936, test acc: 0.959\n",
      "Update #900, train loss: 0.3257, train acc: 0.937, test acc: 0.952\n",
      "Update #1000, train loss: 0.3036, train acc: 0.943, test acc: 0.952\n",
      "Update #1100, train loss: 0.2836, train acc: 0.946, test acc: 0.959\n",
      "Update #1200, train loss: 0.2736, train acc: 0.948, test acc: 0.959\n",
      "Update #1300, train loss: 0.2609, train acc: 0.948, test acc: 0.944\n",
      "Update #1400, train loss: 0.2459, train acc: 0.952, test acc: 0.952\n",
      "Update #1500, train loss: 0.2361, train acc: 0.951, test acc: 0.956\n"
     ]
    }
   ],
   "source": [
    "# Training for one epoch\n",
    "learning_rate = 0.01\n",
    "\n",
    "for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "    lr.train(x, y, learning_rate)\n",
    "    if i % 100 == 0:\n",
    "        train_loss = lr.loss(X_train, y_train)\n",
    "        train_acc = lr.accuracy(X_train, y_train)\n",
    "        test_acc = lr.accuracy(X_test, y_test)\n",
    "        print(\"Update #%d, train loss: %0.4f, train acc: %0.3f, test acc: %0.3f\"\n",
    "              % (i, train_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the first example\n",
    "sample_idx = 0\n",
    "plt.plot(lr.forward(X_train[sample_idx]), linestyle='-', label='prediction')\n",
    "plt.plot(one_hot(10, y_train[sample_idx]), linestyle='--', label='true')\n",
    "plt.title('output probabilities')\n",
    "plt.legend()\n",
    "print(lr.predict(X_train[sample_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Feedforward Multilayer\n",
    "\n",
    "The objective of this section is to implement the backpropagation algorithm (SGD with the chain rule) on a single layer neural network using the sigmoid activation function.\n",
    "\n",
    "- Implement the `sigmoid` and its element-wise derivative `dsigmoid` functions:\n",
    "\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dsigmoid(x) = sigmoid(x) \\cdot (1 - sigmoid(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    # TODO\n",
    "    return X\n",
    "\n",
    "\n",
    "def dsigmoid(X):\n",
    "    # TODO\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFkCAYAAACw3EhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8KTAOeecc6H/AS1t3YtgKv6vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f215f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/sigmoid.py\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "\n",
    "def dsigmoid(X):\n",
    "    sig=sigmoid(X)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "plt.plot(x, sigmoid(x), label='sigmoid')\n",
    "plt.plot(x, dsigmoid(x), label='dsigmoid')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement `forward` and `forward_keep_all` functions for a model with a hidden layer, similar to the first one in Keras:\n",
    "  - $h = sigmoid(\\mathbf{W}^h x + b^h)$\n",
    "  - $y = softmax(\\mathbf{W}^o h + b^o)$\n",
    "\n",
    "Notes: \n",
    "  - try to keep the code as similar as possible as the previous one;\n",
    "  - `forward_keep_activations` is similar to forward, but also returns hidden activations and pre activations;\n",
    "\n",
    "- update the grad function to compute all gradients; check that the gradients are well defined;\n",
    "\n",
    "- implement the `train` and `loss` functions.\n",
    "\n",
    "Bonus: reimplementing all from scratch without looking at the solution of the `LogisticRegression` is an excellent exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-8\n",
    "\n",
    "\n",
    "class NeuralNet():\n",
    "    \"\"\"MLP with 1 hidden layer with a sigmoid activation\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # TODO\n",
    "        self.W_h = np.random.uniform(size=(input_size, output_size), high=0.1, low=-0.1)\n",
    "        self.b_h = None\n",
    "        self.W_o = None\n",
    "        self.b_o = None\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # TODO\n",
    "        if len(X.shape) == 1:\n",
    "            return np.random.uniform(size=self.output_size,\n",
    "                                     high=1.0-EPSILON, low=EPSILON)\n",
    "        else:\n",
    "            return np.random.uniform(size=(X.shape[0], self.output_size),\n",
    "                                     high=1.0-EPSILON, low=EPSILON)\n",
    "    \n",
    "    def forward_keep_activations(self, X):\n",
    "        # TODO\n",
    "        z_h = 0.\n",
    "        h = 0.\n",
    "        y = np.random.uniform(size=self.output_size,\n",
    "                              high=1.0-EPSILON, low=EPSILON)\n",
    "        return y, h, z_h\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        # TODO\n",
    "        return 42.\n",
    "\n",
    "    def grad_loss(self, x, y_true):\n",
    "        # TODO\n",
    "        return {\"W_h\": 0., \"b_h\": 0., \"W_o\": 0., \"b_o\": 0.}\n",
    "\n",
    "    def train(self, x, y, learning_rate):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            return np.argmax(self.forward(x))\n",
    "        else:\n",
    "            return np.argmax(self.forward(x), axis=1)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_preds = np.argmax(self.forward(X), axis=1)\n",
    "        return np.mean(y_preds == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/neural_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden = 10\n",
    "model = NeuralNet(n_features, n_hidden, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.loss(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.accuracy(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "plt.plot(model.forward(X_train[sample_idx]), linestyle='-', label='prediction')\n",
    "plt.plot(one_hot(10, y_train[sample_idx]), linestyle='--', label='true')\n",
    "plt.title('output probabilities')\n",
    "plt.legend()\n",
    "print(model.predict(X_train[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses, accuracies, accuracies_test = [], [], []\n",
    "losses.append(model.loss(X_train, y_train))\n",
    "accuracies.append(model.accuracy(X_train, y_train))\n",
    "accuracies_test.append(model.accuracy(X_test, y_test))\n",
    "\n",
    "print(\"Random init: train loss: %0.4f, train acc: %0.3f, test acc: %0.3f\"\n",
    "      % (losses[-1], accuracies[-1], accuracies_test[-1]))\n",
    "\n",
    "for epoch in range(15):\n",
    "    for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "        model.train(x, y, 0.1)\n",
    "\n",
    "    losses.append(model.loss(X_train, y_train))\n",
    "    accuracies.append(model.accuracy(X_train, y_train))\n",
    "    accuracies_test.append(model.accuracy(X_test, y_test))\n",
    "    print(\"Epoch #%d, train loss: %0.4f, train acc: %0.3f, test acc: %0.3f\"\n",
    "          % (epoch + 1, losses[-1], accuracies[-1], accuracies_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Training loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(accuracies, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Exercises\n",
    "\n",
    "### Hyper parameters settings\n",
    "\n",
    "- Experiment with different hyper parameters:\n",
    "  - learning rate,\n",
    "  - size of hidden layer,\n",
    "  - initialization scheme: test with 0 initialization vs uniform,\n",
    "  - implement other activation functions,\n",
    "  - implement the support for a second hidden layer.\n",
    "\n",
    "\n",
    "### Mini-batches\n",
    "\n",
    "- Bonus: the current implementations of `train` and `grad_loss` function currently only accept a single sample at a time:\n",
    "    - implement the support for training with a mini-batch of 32 samples at a time instead of one,\n",
    "    - experiment with different sizes of batches,\n",
    "    - monitor the norm of the average gradients on the full training set at the end of each epoch.\n",
    "\n",
    "\n",
    "### Momentum\n",
    "\n",
    "- Bonus: Implement momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) TensorFlow Implementation\n",
    "\n",
    "TensorFlow is a symbolic graph computation engine, that allows automatic differentiation of each node\n",
    "- https://www.tensorflow.org \n",
    "- https://www.tensorflow.org/tutorials/mnist/tf/\n",
    "\n",
    "TensorFlow builds where nodes may be:\n",
    "- **constant:** constants tensors, such as a learning rate\n",
    "- **Variables:** any tensor, such as parameters of the models\n",
    "- **Placeholders:** placeholders for inputs and outputs of your models\n",
    "- many other types of nodes (functions, loss, ...)\n",
    "\n",
    "The graph is symbolic, no computation is performed until a `Session` is defined and the command `run` or `eval` is invoked. TensorFlow may run this computation on (multiple) CPUs or GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(2)\n",
    "c = tf.Variable(0)\n",
    "c = a + b\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", name=\"input\")\n",
    "Y = X + tf.constant(3.0)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(Y, feed_dict={X:2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: batches in inputs**\n",
    "- the first dimension of the input is usually kept for the batch dimension. A typical way to define an input placeholder with a 1D tensor of 128 dimensions, is:\n",
    "```\n",
    "X = tf.placeholder(\"float32\", shape=[None, 128])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Build a model using TensorFlow\n",
    "\n",
    "- Using TensorFlow, build a similar model (one hidden layer) as you previously did\n",
    "- the input will be a batch coming from X_train, and the output will be a batch of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y=y_test):\n",
    "    return np.mean(np.argmax(y_pred, axis=1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "batch_size = 32\n",
    "hid_size = 15\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 10\n",
    "\n",
    "# input and output\n",
    "X = tf.placeholder(\"float32\", shape=[None, input_size])\n",
    "y = tf.placeholder(\"int32\", shape=[None])\n",
    "\n",
    "#todo: build the model and weights\n",
    "\n",
    "#todo: build the loss, predict, and train operator\n",
    "# mock loss and b, to change\n",
    "b = init_weights([output_size])\n",
    "loss = b\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "#todo: build predict node\n",
    "predict = X\n",
    "\n",
    "# Initialization of all variables in the graph\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/tf_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    losses = []\n",
    "    for e in range(num_epochs):\n",
    "        for i in range(X_train.shape[0] // batch_size):\n",
    "            # Build batches of batch_size            \n",
    "            idx, idxn = i * batch_size, min(X_train.shape[0]-1, (i+1) * batch_size)\n",
    "            batch_xs, batch_ys = X_train[idx: idxn], y_train[idx: idxn]            \n",
    "            \n",
    "            # Run train operator and monitor loss\n",
    "            _, l=sess.run([train_op, loss], feed_dict={X: batch_xs, y: batch_ys})\n",
    "            losses.append(l)\n",
    "        \n",
    "        # For each epoch, run accuracy on train and test\n",
    "        predicts_test = sess.run(predict, feed_dict={X: X_test})\n",
    "        predicts_train = sess.run(predict, feed_dict={X: X_train})\n",
    "        print(\"epoch: %d train accuracy: %0.3f test accuracy: %0.3f\"\n",
    "              % (e, accuracy(predicts_train, y_train), accuracy(predicts_test)))\n",
    "    \n",
    "    # For monitoring purposes\n",
    "    file_writer = tf.summary.FileWriter('./tensorflow_summaries', sess.graph)    \n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Exercises\n",
    "\n",
    "### Bonus:\n",
    "- add L2 regularization with $\\lambda = 10^{-4}$\n",
    "- train with arbitrary number of layers by only defining layer sizes\n",
    "- you may use tensorboard (https://www.tensorflow.org/how_tos/summaries_and_tensorboard/) to monitor loss and display graph\n",
    "- follow the official tensorflow tutorial: https://www.tensorflow.org/tutorials/mnist/tf/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
